{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e67b6f-7826-4184-9096-84542b1984a3",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Agent-based models by default use so-called **incremental time progression**. This means that the model clock is advanced by a small time step and the state of the model is updated by activating all agents. A major drawback of this is that it can become computationally very expensive for large models with many agents. Moreover, it can be a wasteful approach is it is knoweable in advance what the update will be. \n",
    "\n",
    "For example, in Epstein's civil violence model, if an agent is jailed, every time step, the agent is activated only the reduce the `jail_time_remaining` by 1. However, at the moment of going to jail, it is known when the agent will be released again. So, it would be convenient if it were possible to not active the jailed agents until they are released from prison.\n",
    "\n",
    "Other examples abound. For example, in pandemic simulations, it makes no sense to activate agents when they are at work or say sleeping. In transportation ABMs, likewise, it makes little sense to check each agent, say, every 15 minutes to see if they want to travel. \n",
    "\n",
    "An alternative to **incremental time progression** is **next-event time progression**. In **next-event time progression**, model state updates are done through events. Each event is time stamped. Events are kept in a sorted data structure and the clock advances to the time stamp of the next event, executes the event (which might result in new events being added to the sorted data structure, or *scheduled*). \n",
    "\n",
    "So, in case of the Epstein model, when an agent is arested, one might schedule its *release from jail* event for the current time step plus the jail time duration. While other non-jailed agents just schedule themselves for the current time + 1. Likewise, in pandemic models or transportation models, agents would schedule when they will travel and won't be activated until that travel event is executed.\n",
    "\n",
    "It is also possible to combine **incremental time progression** and **next-event time progression**. That is, one would use **next-event time progression** as is normal in ABMs but add the possibility of scheduling events to occur at given time steps. This offers a flexible hybrid solution, easy to add to existing ABMs, while potentially substantially reducing runtime. \n",
    "\n",
    "Mesa comes with support for both pure **next-event time progression** and this hybrid approach. It's available via `mesa.experimenta.devs`. `devs` stands for discrete event simulation, which is the name of a broad family of simulation methods. ABMs are in essence a particular type of discrete event simulation, but other formalisms next to ABM exist. \n",
    "\n",
    "Below, I have adapted the Epstein model to use the hybrid approach. In short\n",
    "1. I added a `model.free_citizens` attribute, which is an agentset containing the non-jailed agents.\n",
    "2. In `model.step` I only activate the free citizens and the cops\n",
    "3. In the `Citizen`, I added 2 methods: `arrest` and `release`. In `arrest`, I set the state to `ARRESTED`, schedule the release method for the jail time, and remove the citizen from `model.free_citizen`. In `release`, we set the state to `QUIET` and add the agent back to `model.free_citizens`.\n",
    "4. I modified the `Cop` step method to simply call `Citizen.arrest` with the random jail time.\n",
    "5. The way of running a model is a bit different. The run is controlled by an ABMSimulator rather than us calling `model.step`. In the provided code, I run the model for 100 timesteps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76290428-478d-4ea4-b16d-b276885233b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from enum import Enum\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from mesa import Model, Agent\n",
    "from mesa.datacollection import DataCollector\n",
    "from mesa.experimental.cell_space import OrthogonalVonNeumannGrid, CellAgent\n",
    "\n",
    "\n",
    "class CitizenState(Enum):\n",
    "    ACTIVE = 1    \n",
    "    QUIET = 2    \n",
    "    ARRESTED = 3\n",
    "\n",
    "\n",
    "class CivilViolence(Model):\n",
    "    \"\"\"Model class for Eppstein's Civil Violence model I.\n",
    "    \n",
    "    The initial values are from Eppstein's article.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, simulator, height=40, width=40, citizen_density=0.7, citizen_vision=7,\n",
    "        legitimacy=0.82, activation_treshold=0.1, arrest_prob_constant=2.3,\n",
    "        cop_density=0.04, cop_vision=7, max_jail_term=15, seed=None):\n",
    "        super().__init__(seed=seed)\n",
    "        self.simulator = simulator\n",
    "\n",
    "        assert (citizen_density+cop_density) < 1\n",
    "        \n",
    "        # setup Citizen class attributes\n",
    "        Citizen.vision = citizen_vision\n",
    "        Citizen.legitimacy = legitimacy\n",
    "        Citizen.arrest_prob_constant = arrest_prob_constant\n",
    "        Citizen.activation_threshold = activation_treshold\n",
    "        \n",
    "        # setup Cop class attributes\n",
    "        Cop.vision = cop_vision\n",
    "        Cop.max_jail_term = max_jail_term\n",
    "\n",
    "        # setup data collection\n",
    "        model_reporters = {'active': CitizenState.ACTIVE.name,\n",
    "                           'quiet': CitizenState.QUIET.name,\n",
    "                           'arrested': CitizenState.ARRESTED.name}\n",
    "\n",
    "        # populate agents\n",
    "        self.datacollector = DataCollector(model_reporters=model_reporters)\n",
    "        self.grid = OrthogonalVonNeumannGrid((width, height), capacity=1,\n",
    "                                        torus=True, random=self.random)\n",
    "\n",
    "        # Set up agents\n",
    "        for cell in self.grid.all_cells:\n",
    "            klass = self.random.choices([Citizen, Cop, None],\n",
    "                                   cum_weights=[citizen_density,\n",
    "                                                citizen_density+cop_density, 1])[0]\n",
    "            if klass: \n",
    "                agent = klass(self)\n",
    "                agent.cell = cell\n",
    "\n",
    "        self.free_citizens = self.agents_by_type[Citizen]\n",
    "        \n",
    "        self._update_counts()\n",
    "        self.datacollector.collect(self)\n",
    "\n",
    "    def _update_counts(self):\n",
    "        for state, count in self.agents_by_type[Citizen].groupby(\"state\").count().items():\n",
    "            setattr(self, state.name, count)\n",
    "        \n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Run one step of the model.\n",
    "        \"\"\"\n",
    "        self.free_citizens.shuffle_do(\"step\")\n",
    "        self.agents_by_type[Cop].shuffle_do(\"step\")\n",
    "        self._update_counts()        \n",
    "        self.datacollector.collect(self)\n",
    "\n",
    "\n",
    "class BaseAgent(CellAgent):\n",
    "    '''Base Agent class implementing vision and moving\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    moore : boolean\n",
    "    \n",
    "    '''    \n",
    "    \n",
    "    def get_agents_in_vision(self):\n",
    "        \"\"\"\n",
    "        identify cops and active citizens within vision\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        tuple with list of cops, and list of active citizens\n",
    "        \n",
    "        \"\"\"\n",
    "        cops = []\n",
    "        active_citizens = []\n",
    "        \n",
    "        for agent in self.cell.get_neighborhood(radius=self.__class__.vision).agents:\n",
    "            if isinstance(agent, Cop):\n",
    "                cops.append(agent)\n",
    "            elif agent.state == CitizenState.ACTIVE:\n",
    "                active_citizens.append(agent)    \n",
    "        return cops, active_citizens\n",
    "    \n",
    "    def move(self):\n",
    "        \"\"\"Identify all empty cells within vision and move to a randomly selected one.\"\"\"\n",
    "        empty = [cell for cell in self.cell.get_neighborhood(radius=self.__class__.vision) \n",
    "                 if cell.is_empty]\n",
    "        \n",
    "        if empty:\n",
    "            self.cell = self.random.choice(empty)\n",
    "        \n",
    "    \n",
    "class Citizen(BaseAgent):\n",
    "    '''Citizen class\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    legitimacy : boolean\n",
    "    vision : int\n",
    "    arrest_prob_constant : float\n",
    "    activation_treshold : float\n",
    "    hardship : float\n",
    "    risk_aversion : float\n",
    "    state : {CitizenState.QUIET, CitizenState.ACTIVE, CitizenState.ARRESTED }\n",
    "    jail_time_remaining  :int\n",
    "    grievance : float\n",
    "    \n",
    "    '''        \n",
    "    legitimacy = 1\n",
    "    vision = 1\n",
    "    arrest_prob_constant = 1\n",
    "    activation_treshold = 1\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        super().__init__(model)\n",
    "        self.hardship = self.random.random()\n",
    "        self.risk_aversion = self.random.random()\n",
    "        self.state = CitizenState.QUIET\n",
    "        self.grievance = self.hardship*(1-Citizen.legitimacy)\n",
    "\n",
    "\n",
    "    def arrest(self, jail_time):\n",
    "        self.state = CitizenState.ARRESTED\n",
    "        self.model.free_citizens.remove(self)\n",
    "        self.model.simulator.schedule_event_relative(self.release, jail_time)\n",
    "\n",
    "    def release(self):\n",
    "        self.state = CitizenState.QUIET\n",
    "        self.model.free_citizens.add(self)\n",
    "    \n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        move and then decide whether to activate\n",
    "        \"\"\"         \n",
    "        self.move()\n",
    "            \n",
    "        cops, active_citizens = self.get_agents_in_vision()\n",
    "        n_cops = len(cops)\n",
    "        n_active_citizens = len(active_citizens) + 1 # self is always considerd active\n",
    "            \n",
    "        arrest_p = 1 - math.exp(-1*Citizen.arrest_prob_constant * round(n_cops/n_active_citizens))\n",
    "        net_risk = self.risk_aversion * arrest_p\n",
    "        \n",
    "        if (self.grievance - net_risk) > self.activation_threshold:\n",
    "            self.state = CitizenState.ACTIVE\n",
    "        else:\n",
    "            self.state = CitizenState.QUIET\n",
    "        \n",
    "\n",
    "class Cop(BaseAgent):\n",
    "    '''Cop class\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    vision : int\n",
    "    max_jail_term : int\n",
    "    '''\n",
    "    vision = 1\n",
    "    max_jail_term = 1\n",
    "        \n",
    "    def step(self):\n",
    "        self.move()\n",
    "        _, active_citizens = self.get_agents_in_vision()\n",
    "        \n",
    "        if active_citizens:\n",
    "            citizen = self.random.choice(active_citizens)\n",
    "            citizen.arrest(self.random.randint(0, Cop.max_jail_term))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f48b927-33ed-4b0e-83cc-a81fbe4353eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mesa.experimental.devs import ABMSimulator\n",
    "\n",
    "simulator = ABMSimulator()\n",
    "model = CivilViolence(\n",
    "    simulator,\n",
    "    seed=15,\n",
    ")\n",
    "\n",
    "simulator.setup(model)\n",
    "simulator.run_for(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae4e926-6c4b-4c1d-bf7a-139f11d29c71",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Compare the runtime of this hybrid event scheduling with incremental time progression version of the model to the model from last week. You can use the time module for this as shown below, or use a `%%timeit` jupyter cell magic. \n",
    "\n",
    "```python\n",
    "import time\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "simulator.run_for(100)\n",
    "print(\"Time:\", time.perf_counter() - start_time)\n",
    "\n",
    "# or in jupyter lab\n",
    "%%timeit\n",
    "simulator.run_for(100)\n",
    "```\n",
    "\n",
    "1. How large is the difference in runtime?\n",
    "2. Can you think of other ways of using event scheduling in this model to further speed up the model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce023c1c-4c63-48dc-8725-40ca0be3eba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bf35335-4ee1-42b3-a20e-49afc8314a72",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "Below, I give you the wolf sheep grass example model that comes with mesa. This model can also be substantially sped up by using event scheduling. \n",
    "\n",
    "1. Adapt the provided model to use event scheduling for the grass regrowth dynamics. That is, whenever the grass get's eaten, it should schedule an event for it to be fully regrown.\n",
    "2. Compare the runtime between both versions of the model for 100 timesteps, account for the stochastic nature of the model in this runtime comparison. Plot the runtime of both models using histograms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f03473ab-88da-4342-9804-e7f625b4e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mesa\n",
    "from mesa.experimental.cell_space import CellAgent, FixedAgent\n",
    "from mesa.experimental.cell_space import OrthogonalMooreGrid\n",
    "\n",
    "class Animal(CellAgent):\n",
    "    \"\"\"The base animal class.\"\"\"\n",
    "\n",
    "    def __init__(self, model, energy, p_reproduce, energy_from_food, cell):\n",
    "        \"\"\"Initializes an animal.\n",
    "\n",
    "        Args:\n",
    "            model: a model instance\n",
    "            energy: starting amount of energy\n",
    "            p_reproduce: probability of sexless reproduction\n",
    "            energy_from_food: energy obtained from 1 unit of food\n",
    "            cell: the cell in which the animal starts\n",
    "        \"\"\"\n",
    "        super().__init__(model)\n",
    "        self.energy = energy\n",
    "        self.p_reproduce = p_reproduce\n",
    "        self.energy_from_food = energy_from_food\n",
    "        self.cell = cell\n",
    "\n",
    "    def spawn_offspring(self):\n",
    "        \"\"\"Create offspring.\"\"\"\n",
    "        self.energy /= 2\n",
    "        self.__class__(\n",
    "            self.model,\n",
    "            self.energy,\n",
    "            self.p_reproduce,\n",
    "            self.energy_from_food,\n",
    "            self.cell,\n",
    "        )\n",
    "\n",
    "    def feed(self): ...\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"One step of the agent.\"\"\"\n",
    "        self.cell = self.cell.neighborhood.select_random_cell()\n",
    "        self.energy -= 1\n",
    "\n",
    "        self.feed()\n",
    "\n",
    "        if self.energy < 0:\n",
    "            self.remove()\n",
    "        elif self.random.random() < self.p_reproduce:\n",
    "            self.spawn_offspring()\n",
    "\n",
    "\n",
    "class Sheep(Animal):\n",
    "    \"\"\"A sheep that walks around, reproduces (asexually) and gets eaten.\"\"\"\n",
    "\n",
    "    def feed(self):\n",
    "        \"\"\"If possible eat the food in the current location.\"\"\"\n",
    "        # If there is grass available, eat it\n",
    "        if self.model.grass:\n",
    "            grass_patch = next(\n",
    "                obj for obj in self.cell.agents if isinstance(obj, GrassPatch)\n",
    "            )\n",
    "            if grass_patch.fully_grown:\n",
    "                self.energy += self.energy_from_food\n",
    "                grass_patch.fully_grown = False\n",
    "\n",
    "\n",
    "class Wolf(Animal):\n",
    "    \"\"\"A wolf that walks around, reproduces (asexually) and eats sheep.\"\"\"\n",
    "\n",
    "    def feed(self):\n",
    "        \"\"\"If possible eat the food in the current location.\"\"\"\n",
    "        sheep = [obj for obj in self.cell.agents if isinstance(obj, Sheep)]\n",
    "        if len(sheep) > 0:\n",
    "            sheep_to_eat = self.random.choice(sheep)\n",
    "            self.energy += self.energy_from_food\n",
    "\n",
    "            # Kill the sheep\n",
    "            sheep_to_eat.remove()\n",
    "\n",
    "\n",
    "class GrassPatch(FixedAgent):\n",
    "    \"\"\"\n",
    "    A patch of grass that grows at a fixed rate and it is eaten by sheep\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, fully_grown, countdown):\n",
    "        \"\"\"\n",
    "        Creates a new patch of grass\n",
    "\n",
    "        Args:\n",
    "            grown: (boolean) Whether the patch of grass is fully grown or not\n",
    "            countdown: Time for the patch of grass to be fully grown again\n",
    "        \"\"\"\n",
    "        super().__init__(model)\n",
    "        self.fully_grown = fully_grown\n",
    "        self.countdown = countdown\n",
    "\n",
    "    def step(self):\n",
    "        if not self.fully_grown:\n",
    "            if self.countdown <= 0:\n",
    "                # Set as fully grown\n",
    "                self.fully_grown = True\n",
    "                self.countdown = self.model.grass_regrowth_time\n",
    "            else:\n",
    "                self.countdown -= 1\n",
    "\n",
    "class WolfSheep(mesa.Model):\n",
    "    \"\"\"\n",
    "    Wolf-Sheep Predation Model\n",
    "    \"\"\"\n",
    "\n",
    "    height = 20\n",
    "    width = 20\n",
    "\n",
    "    initial_sheep = 100\n",
    "    initial_wolves = 50\n",
    "\n",
    "    sheep_reproduce = 0.04\n",
    "    wolf_reproduce = 0.05\n",
    "\n",
    "    wolf_gain_from_food = 20\n",
    "\n",
    "    grass = False\n",
    "    grass_regrowth_time = 30\n",
    "    sheep_gain_from_food = 4\n",
    "\n",
    "    description = (\n",
    "        \"A model for simulating wolf and sheep (predator-prey) ecosystem modelling.\"\n",
    "    )\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        width=20,\n",
    "        height=20,\n",
    "        initial_sheep=100,\n",
    "        initial_wolves=50,\n",
    "        sheep_reproduce=0.04,\n",
    "        wolf_reproduce=0.05,\n",
    "        wolf_gain_from_food=20,\n",
    "        grass=False,\n",
    "        grass_regrowth_time=30,\n",
    "        sheep_gain_from_food=4,\n",
    "        seed=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Create a new Wolf-Sheep model with the given parameters.\n",
    "\n",
    "        Args:\n",
    "            initial_sheep: Number of sheep to start with\n",
    "            initial_wolves: Number of wolves to start with\n",
    "            sheep_reproduce: Probability of each sheep reproducing each step\n",
    "            wolf_reproduce: Probability of each wolf reproducing each step\n",
    "            wolf_gain_from_food: Energy a wolf gains from eating a sheep\n",
    "            grass: Whether to have the sheep eat grass for energy\n",
    "            grass_regrowth_time: How long it takes for a grass patch to regrow\n",
    "                                 once it is eaten\n",
    "            sheep_gain_from_food: Energy sheep gain from grass, if enabled.\n",
    "        \"\"\"\n",
    "        super().__init__(seed=seed)\n",
    "        # Set parameters\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.initial_sheep = initial_sheep\n",
    "        self.initial_wolves = initial_wolves\n",
    "        self.grass = grass\n",
    "        self.grass_regrowth_time = grass_regrowth_time\n",
    "\n",
    "        self.grid = OrthogonalMooreGrid((self.width, self.height), torus=True)\n",
    "\n",
    "        collectors = {\n",
    "            \"Wolves\": lambda m: len(m.agents_by_type[Wolf]),\n",
    "            \"Sheep\": lambda m: len(m.agents_by_type[Sheep]),\n",
    "            \"Grass\": lambda m: len(\n",
    "                m.agents_by_type[GrassPatch].select(lambda a: a.fully_grown)\n",
    "            )\n",
    "            if m.grass\n",
    "            else -1,\n",
    "        }\n",
    "\n",
    "        self.datacollector = mesa.DataCollector(collectors)\n",
    "\n",
    "        # Create sheep:\n",
    "        for _ in range(self.initial_sheep):\n",
    "            x = self.random.randrange(self.width)\n",
    "            y = self.random.randrange(self.height)\n",
    "            energy = self.random.randrange(2 * self.sheep_gain_from_food)\n",
    "            Sheep(\n",
    "                self, energy, sheep_reproduce, sheep_gain_from_food, self.grid[(x, y)]\n",
    "            )\n",
    "\n",
    "        # Create wolves\n",
    "        for _ in range(self.initial_wolves):\n",
    "            x = self.random.randrange(self.width)\n",
    "            y = self.random.randrange(self.height)\n",
    "            energy = self.random.randrange(2 * self.wolf_gain_from_food)\n",
    "            Wolf(self, energy, wolf_reproduce, wolf_gain_from_food, self.grid[(x, y)])\n",
    "\n",
    "        # Create grass patches\n",
    "        if self.grass:\n",
    "            for cell in self.grid.all_cells:\n",
    "                fully_grown = self.random.choice([True, False])\n",
    "\n",
    "                if fully_grown:\n",
    "                    countdown = self.grass_regrowth_time\n",
    "                else:\n",
    "                    countdown = self.random.randrange(self.grass_regrowth_time)\n",
    "\n",
    "                patch = GrassPatch(self, fully_grown, countdown)\n",
    "                patch.cell = cell\n",
    "\n",
    "        self.running = True\n",
    "        self.datacollector.collect(self)\n",
    "\n",
    "    def step(self):\n",
    "        self.random.shuffle(self.agent_types)\n",
    "        for agent_type in self.agent_types:\n",
    "            self.agents_by_type[agent_type].shuffle_do(\"step\")\n",
    "\n",
    "        # collect data\n",
    "        self.datacollector.collect(self)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "869991c7-3caf-418d-be8a-39f71575f70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.013883625004382338\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "model = WolfSheep(seed=42)  # this is only 1 deterministic stochastic realization\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "for _  in range(100):\n",
    "    model.step()\n",
    "print(\"Time:\", time.perf_counter() - start_time)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1047f01-d992-45a0-b494-9acb11cfe3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
