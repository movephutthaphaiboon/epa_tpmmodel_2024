{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# The importance of space\n",
    "Agent based models are useful when the aggregate system behavior emerges out of local interactions amongst the agents. In the model of the evolution of cooperation, we created a set of agents and let all agents play against all other agents. Basically, we pretended as if all our agents were perfectly mixed. In practice, however, it is much more common that agents only interact with some, but not all, other agents. For example, in models of epidemiology, social interactions are a key factors. Thus, interactions are dependend on your social network. In other situations, our behavior might be based on what we see around us. Phenomena like fashion are at least partly driven by seeing what others are doing and mimicking this behavior. The same is true for many animals. Flocking dynamics as exhibited by starling, or shoaling behavior in fish, can be explained by the animal looking at its neirest neighbors and staying within a given distance of them. In agent based models, anything that structures the interaction amongst agents is typically called a space. This space can be a 2d or 3d space with euclidian distances (as in models of flocking and shoaling), it can also be a grid structure (as we will show below), or it can be a network structure. \n",
    "\n",
    "MESA comes with several spaces that we can readily use. These are\n",
    "\n",
    "* **Grid** Think of this of an excel like space.In this course, we use the new experimental cell spaces. With these, Mesa distinguishes between 3 types of grids: `OrthogonalMooreGrid`, `OrthogonalVonNeumanGrid`, and `HexGrid`. A moore grid is an excel like grid where each cell has 8 neighbors. A OrthogonalVonNeumanGrid were each cell has 4 neighbors, and a HexGrid which is a Catan like grid were each cell has 6 neighbors.\n",
    "* **ConinuousSpace;** a 2d continous space were agents can occupy any coordinate\n",
    "* **Network;** a network structure were one or more agents occupy a given node.\n",
    "\n",
    "A key concern when using a none-networked space, is to think carefull about what happens at the edges of the space. In a basic implementation, agents in for example the top left corner has only 2 neighbors, while an agent in the middle has four neighbors. This can give rise to artifacts in the results. Basically, the dynamics at the edges are different from the behavior further away from the edges. It is therefore quite common to use a torus, or donut, shape for the space. In this way, there is no longer any edge and artifacts are thus removed.\n",
    "\n",
    "\n",
    "# The emergence of cooperation in space\n",
    "In this assignment, we'll use an `OrthogonalMooreSpace`. Most of what is covered here translated direclty to the other types of grids. \n",
    "\n",
    "We make the following changes to the model\n",
    "\n",
    "* The model has a grid, with an agent of random class. We initialize the model with equal probabilities for each type of class\n",
    "* All agents play against their neighbors. On a grid, neighborhood can be defined in various ways. Below, we use a neighborhood distance of 1, and we do include diagonal neighbors (so we use a Moore grid, rather than a von Neumann grid which has 4 neighbors).\n",
    "* The evolutionary dynamic, after all agents having played, is that each agent compares its scores to its neighbors. It will adopt whichever strategy within its neighborhood performed best.\n",
    "* Next to using a Grid from MESA, we also use a DataCollector to handle collecting statistics.\n",
    "\n",
    "Below, I discuss in more detail the code containing the most important modifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T14:11:28.153915Z",
     "start_time": "2020-10-09T14:11:21.425797Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import deque, Counter, defaultdict\n",
    "from enum import Enum\n",
    "from itertools import combinations\n",
    "from math import floor\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from mesa import Model, Agent\n",
    "from mesa.datacollection import DataCollector\n",
    "\n",
    "from mesa.experimental.cell_space import CellAgent, OrthogonalMooreGrid\n",
    "\n",
    "class Move(Enum):\n",
    "    COOPERATE = 1\n",
    "    DEFECT = 2\n",
    "\n",
    "\n",
    "class AxelrodAgent(CellAgent):\n",
    "    \"\"\"An agent with fixed initial wealth.\"\"\"\n",
    "\n",
    "    def __init__(self, model, n_rounds, noise_level=0): \n",
    "        super().__init__(model)\n",
    "        self.n_rounds = n_rounds\n",
    "        self.points = 0\n",
    "        self.noise_level = noise_level\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Playing the iterated prisoners dilemma agains all other agents in the model\"\"\"\n",
    "        for other in self.cell.neighborhood.agents:\n",
    "            for _ in range(self.n_rounds):\n",
    "                move_a = self.move()\n",
    "                move_b = other.move()\n",
    "    \n",
    "                #insert noise in movement, we\n",
    "                if self.random.random() < self.noise_level:\n",
    "                    if move_a == Move.COOPERATE:\n",
    "                        move_a = Move.DEFECT\n",
    "                    else:\n",
    "                        move_a = Move.COOPERATE\n",
    "                if self.random.random() < self.noise_level:\n",
    "                    if move_b == Move.COOPERATE:\n",
    "                        move_b = Move.DEFECT\n",
    "                    else:\n",
    "                        move_b = Move.COOPERATE                \n",
    "                \n",
    "                payoff_a, payoff_b = self.model.payoff_matrix[(move_a, move_b)]\n",
    "                \n",
    "                self.receive_payoff(payoff_a, move_a, move_b)\n",
    "                other.receive_payoff(payoff_b, move_b, move_a)\n",
    "            self.reset()\n",
    "            other.reset()\n",
    "\n",
    "    def move(self):\n",
    "        \"\"\"The move to make in this iteration of the game\n",
    "        \n",
    "        Returns:\n",
    "            Move.COOPERATE or Move.DEFECT\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def receive_payoff(self, payoff, my_move, opponent_move):\n",
    "        \"\"\"Receive payoff and moves resulting in that payoff.\n",
    "\n",
    "        Args:\n",
    "            payoff : int\n",
    "            my_move : {Move.COOPERATE, Move.DEFECT}\n",
    "            opponements_move : {Move.COOPERATE, Move.DEFECT}\n",
    "\n",
    "        \"\"\"\n",
    "        self.points += payoff\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Called after playing N iterations agains another player.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class TitForTat(AxelrodAgent):\n",
    "    def __init__(self, model, n_rounds, noise_level=0):\n",
    "        super().__init__(model, n_rounds, noise_level=noise_level)\n",
    "        self.opponent_last_move = Move.COOPERATE\n",
    "\n",
    "    def move(self):\n",
    "        return self.opponent_last_move\n",
    "\n",
    "    def receive_payoff(self, payoff, my_move, opponent_move):\n",
    "        super().receive_payoff(payoff, my_move, opponent_move)\n",
    "        self.opponent_last_move = opponent_move\n",
    "\n",
    "    def reset(self):\n",
    "        self.opponent_last_move = Move.COOPERATE\n",
    "\n",
    "\n",
    "class ContriteTitForTat(AxelrodAgent):\n",
    "    def __init__(self, model, n_rounds, noise_level=0):\n",
    "        super().__init__(model, n_rounds, noise_level=noise_level)\n",
    "        self.opponent_last_two_moves = deque([Move.COOPERATE, Move.COOPERATE], maxlen=2)\n",
    "\n",
    "    def move(self):\n",
    "        if (self.opponent_last_two_moves[0] == Move.DEFECT) and (\n",
    "            self.opponent_last_two_moves[1] == Move.DEFECT\n",
    "        ):\n",
    "            return Move.DEFECT\n",
    "        else:\n",
    "            return Move.COOPERATE\n",
    "\n",
    "    def receive_payoff(self, payoff, my_move, opponent_move):\n",
    "        super().receive_payoff(payoff, my_move, opponent_move)\n",
    "        self.opponent_last_two_moves.append(opponent_move)\n",
    "\n",
    "    def reset(self):\n",
    "        self.opponent_last_two_moves = deque([Move.COOPERATE, Move.COOPERATE], maxlen=2)\n",
    "\n",
    "\n",
    "class NoisySpatialEvolutionaryAxelrodModel(Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n=100,\n",
    "        noise_level=0.01,\n",
    "        seed=None,\n",
    "        height=20,\n",
    "        width=20,\n",
    "    ):\n",
    "        super().__init__(seed=seed)\n",
    "        self.noise_level = noise_level\n",
    "        self.num_iterations = n\n",
    "        \n",
    "        self.payoff_matrix = {\n",
    "            (Move.COOPERATE, Move.COOPERATE):(2, 2),\n",
    "            (Move.COOPERATE, Move.DEFECT): (0, 3),\n",
    "            (Move.DEFECT, Move.COOPERATE): (3, 0),\n",
    "            (Move.DEFECT, Move.DEFECT): (1, 1)\n",
    "        }\n",
    "        \n",
    "        self.grid = OrthogonalMooreGrid((width, height), torus=True, capacity=1, random=self.random)\n",
    "        strategies = AxelrodAgent.__subclasses__()\n",
    "\n",
    "        for cell in self.grid.all_cells:\n",
    "            strategy = self.random.choice(strategies)\n",
    "            agent = strategy(self, self.num_iterations, noise_level=self.noise_level) \n",
    "            agent.cell = cell\n",
    "\n",
    "        # also needed by MESA, and useful for tracking the number of agents for each strategy\n",
    "        self.datacollector = DataCollector(\n",
    "            model_reporters={klass.__name__: klass.__name__ for klass in strategies}\n",
    "        )\n",
    "        self.count_agent_types()\n",
    "        self.datacollector.collect(self)\n",
    "\n",
    "    def count_agent_types(self):\n",
    "        counter = self.agents.groupby(type).count()\n",
    "        \n",
    "        for k, v in counter.items():\n",
    "            setattr(self, k.__name__, v)\n",
    "\n",
    "    \n",
    "    def step(self):\n",
    "        \"\"\"Advance the model by one step.\"\"\"\n",
    "        self.agents.do(\"step\")\n",
    "        \n",
    "        # evolution\n",
    "        # tricky, we need to determine for each grid cell\n",
    "        # is a change needed, if so, log position, agent, and type to change to\n",
    "        agents_to_change = []\n",
    "        for agent_a in self.agents:\n",
    "            neigbors = list(agent_a.cell.neighborhood.agents)\n",
    "            neigbors.sort(key=lambda x: x.points, reverse=True)\n",
    "            best_strategy = neigbors[0].__class__\n",
    "            best_score = neigbors[0].points\n",
    "            \n",
    "            if best_score > agent_a.points and not isinstance(agent_a, best_strategy):\n",
    "                agents_to_change.append((agent_a, best_strategy))\n",
    "\n",
    "        for entry in agents_to_change:\n",
    "            agent, klass = entry\n",
    "            cell = agent.cell\n",
    "            \n",
    "            # remove agent\n",
    "            agent.remove()\n",
    "\n",
    "            new_agent = klass(self, self.num_iterations, noise_level=self.noise_level) \n",
    "            new_agent.cell = cell\n",
    "\n",
    "        self.count_agent_types()\n",
    "        self.datacollector.collect(self)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to visualize and animate this model withint the notebook (see also the first week's tutorial), we need to specify the attributes schedule, grid, and datacollector.\n",
    "\n",
    "\n",
    "In the `__init__`, we now instantiate an `OrthogonalMooreGrid`, with a specified width and height. We set the kwarg torus to True indicating we are using a donut shape grid to avoid edge effects. Next, we fill this grid with random agents of the different types. This can be implemented in various ways. What I do here is using a list with the different classes (*i.e.*, types of strategies) and draw a random element from this list via `self.random.choice`. So, we iterate over all cells in the grid, for each cell we draw a random strategy class, instantiate the class and assign the cell to it.\n",
    "\n",
    "\n",
    "```python\n",
    "    self.grid = OrthogonalMooreGrid((width, height), torus=True, capacity=1, random=self.random)\n",
    "    strategies = AxelrodAgent.__subclasses__()\n",
    "\n",
    "    for cell in self.grid.all_cells:\n",
    "        strategy = self.random.choice(strategies)\n",
    "        agent = strategy(self, self.num_iterations, noise_level=self.noise_level) \n",
    "        agent.cell = cell\n",
    "```\n",
    "\n",
    "We also use a DataCollector. This is a default class provided by MESA that can be used for keeping track of relevant statistics. It can store both model level variables as well as agent level variables. Here we are only using model level variables (i.e. attributes of the model). Specifically, we are going to have an attribute on the model for each type of agent strategy (i.e. classes). This attribute is the current count of agents in the grid of the specific type. To implement this, we need to do several things.\n",
    "\n",
    "1. initialize a data collector instance\n",
    "2. at every step update the current count of agents of each strategy\n",
    "3. collect the current counts with the data collector.\n",
    "\n",
    "For step 1, we set a DataCollector as an attribute. This datacollector needs to know the names of the attributes on the model it needs to collect. So we pass a dict as kwarg to model_reporters. This dict has as key the name by which the variable will be known in the DataCollector. As value, I pass the name of the attribute on the model, but it can also be a function or method which returns a number. Note that the ``klass`` misspelling is deliberate. The word ``class`` is protected in Python, so you cannot use it as a variable name. It is common practice to use ``klass`` instead in the rare cases were you are having variable refering to a specific class.\n",
    "\n",
    "```python\n",
    "self.datacollector = DataCollector(model_reporters={klass.__name__:klass.__name__\n",
    "                                                    for klass in strategies})\n",
    "```\n",
    "\n",
    "For step 2, we need to count at every step the number of agents per strategy type. To help keep track of this, we define a new method, `count_agent_types`. The main magic is the use of `setattr` which is a standard python function for setting attributes to a particular value on a given object. This reason for writing our code this way is that we automatically adapt our attributes to the classes of agents we have, rather than hardcoding the agent classes as attributes on our model. If we now add new classes of agents, we don't need to change the model code itself. There is also a ``getattr`` function, which is used by for example the DataCollector to get the values for the specified attribute names. \n",
    "\n",
    "```python\n",
    "def count_agent_types(self):\n",
    "    counter = self.agents.groupby(type).count()\n",
    "\n",
    "    for k,v in counter.items():\n",
    "        setattr(self, k.__name__, v)    \n",
    "\n",
    "```\n",
    "\n",
    "We have to add the evolutionary dynamic. This is a bit tricky. In `NoisySpatialEvolutionaryAxelrodModel.step`, we loop over all agents in the model. We check its neighbors and see which strategy performed best. If this is of a different type (``not isinstance(agent_a, best_strategy)``, we add it to a list of agents that needs to be changed and the type of agent to which it needs to be changed. Once we know all agents that need to be changed, we can make this change. \n",
    "\n",
    "Making the change is quite straighforward. We first make sure we track the cell to which the agent was assigned. Next, we call `agent.remove()`, this is a default method in MESA for removing agents from the model. Since `AxelrodAgent` subclasses CellAgent, calling `agent.remove` removes the agent not just from the model, but also from our space. Then we can create a new agent of the correct class and assign the now empty cell to this new agent.\n",
    "\n",
    "```python\n",
    "# evolution\n",
    "agents_to_change = []\n",
    "agents_to_change = []\n",
    "for agent_a in self.agents:\n",
    "    neigbors = list(agent_a.cell.neighborhood.agents)\n",
    "    neigbors.sort(key=lambda x: x.points, reverse=True)\n",
    "    best_strategy = neigbors[0].__class__\n",
    "    best_score = neigbors[0].points\n",
    "    \n",
    "    if best_score > agent_a.points and not isinstance(agent_a, best_strategy):\n",
    "        agents_to_change.append((agent_a, best_strategy))\n",
    "\n",
    "for entry in agents_to_change:\n",
    "    agent, klass = entry\n",
    "    cell = agent.cell\n",
    "    \n",
    "    # remove agent\n",
    "    agent.remove()\n",
    "\n",
    "    new_agent = klass(self, self.num_iterations, noise_level=self.noise_level) \n",
    "    new_agent.cell = cell\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mesa.visualization import (\n",
    "    SolaraViz,\n",
    "    make_plot_component,\n",
    "    make_space_component,\n",
    ")\n",
    "\n",
    "# using tableau colors as defined in matplotlib (https://matplotlib.org/stable/users/explain/colors/colors.html)\n",
    "agent_to_color = {TitForTat.__name__:'tab:blue', ContriteTitForTat.__name__:'tab:orange'}\n",
    "\n",
    "\n",
    "def agent_portrayal(agent):\n",
    "    size = 150\n",
    "    color = agent_to_color[agent.__class__.__name__]\n",
    "    return {\"size\": size, \"color\": color}\n",
    "\n",
    "model_params = {\n",
    "    \"n\": {\n",
    "        \"type\": \"SliderInt\",\n",
    "        \"value\": 50,\n",
    "        \"label\": \"Number of rounds:\",\n",
    "        \"min\": 10,\n",
    "        \"max\": 100,\n",
    "        \"step\": 1,\n",
    "    },\n",
    "    \"noise_level\": {\n",
    "        \"type\": \"SliderFloat\",\n",
    "        \"value\": 0.01,\n",
    "        \"label\": \"noise level:\",\n",
    "        \"min\": 0.001,\n",
    "        \"max\": 0.2,\n",
    "        \"step\": 0.001\n",
    "    },\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# Create initial model instance\n",
    "model = NoisySpatialEvolutionaryAxelrodModel(n=50, width=10, height=10)\n",
    "\n",
    "\n",
    "SpaceGraph = make_space_component(agent_portrayal)\n",
    "N_AgentsPlot = make_plot_component(list(agent_to_color.keys()))\n",
    "\n",
    "page = SolaraViz(\n",
    "    model,\n",
    "    components=[SpaceGraph, N_AgentsPlot],\n",
    "    model_params=model_params,\n",
    "    name=\"Axelrod\",\n",
    ")\n",
    "\n",
    "# This is required to render the visualization in the Jupyter notebook\n",
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Assignment 1\n",
    "Can you explain why we need to first loop over all agents before we are changing a given agent to a different strategy?\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "Add all agents classes (i.e., strategy) from the previous assignment to this model. Note that you might have to update the ``__init__`` method to reflect the new pos keyword argument and attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T14:11:19.467048Z",
     "start_time": "2020-10-09T14:11:19.409142Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Assignment 3\n",
    "Run the model for 50 steps, and with 200 rounds of the iterated game. Use the defaults for all other keyword arguments.\n",
    "\n",
    "Plot the results. \n",
    "\n",
    "*hint: you need to update the agent_to_color to ensure all strategies are included. You can use `AxelrodAgent.__subclasses__()` to get all strategies*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_to_color = {TitForTat.__name__:\"tab:blue\",\n",
    "                  ContriteTitForTat.__name__:\"tab:orange\",\n",
    "                  ...\n",
    "                 }\n",
    "\n",
    "# Create initial model instance\n",
    "model = NoisySpatialEvolutionaryAxelrodModel(n=50, width=10, height=10)\n",
    "\n",
    "\n",
    "SpaceGraph = make_space_matplotlib(agent_portrayal)\n",
    "N_AgentsPlot = make_plot_measure(list(agent_to_color.keys()))\n",
    "\n",
    "page = SolaraViz(\n",
    "    model,\n",
    "    components=[SpaceGraph, N_AgentsPlot],\n",
    "    model_params=model_params,\n",
    "    name=\"Axelrod\",\n",
    ")\n",
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new model is quite a bit noisier than previously. We have a random initialization of the grid and depending on the initial neighborhood, different evolutionary dynamics can happen. On top, we have the noise in game play, and the Random agent. \n",
    "\n",
    "\n",
    "## Assignment 4\n",
    "Let's explore the model for 10 replications. Run the model 10 times, with 200 rounds of the iterated prisoners dilemma. Run each model for fifty steps. Plot the results for each run. \n",
    "\n",
    "1. Can you say anything generalizable about the behavioral dynamics of the model?\n",
    "2. What do you find striking in the results and why?\n",
    "3. If you compare the results for this spatially explicit version of the Emergence of Cooperation with the none spatially explicit version, what are the most important differences in dynamics. Can you explain why adding local interactions results in these changes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    model = NoisySpatialEvolutionaryAxelrodModel(n=200)\n",
    "    for _ in range(50):\n",
    "        model.step()\n",
    "    model.datacollector.get_model_vars_dataframe().plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
